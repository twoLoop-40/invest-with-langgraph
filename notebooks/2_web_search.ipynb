{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": "# ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ì£¼ì‹ íˆ¬ì ì±—ë´‡\n\n## í•™ìŠµ ëª©í‘œ\nì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ë‹¤ìŒ ë‚´ìš©ì„ ë°°ì›ë‹ˆë‹¤:\n- LangGraphì˜ ì¡°ê±´ë¶€ ì—£ì§€(Conditional Edge) ì‚¬ìš©ë²•\n- Tavily ì›¹ ê²€ìƒ‰ API í™œìš©\n- State ê¸°ë°˜ ë°˜ë³µ ì œì–´ (ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜)\n- Context ëˆ„ì  ë° í‰ê°€ ê¸°ë°˜ ì˜ì‚¬ê²°ì •\n- Pydanticì„ ì‚¬ìš©í•œ êµ¬ì¡°í™”ëœ ì¶œë ¥\n\n## ì£¼ìš” ê°œì„ ì‚¬í•­\n- LLM ëª¨ë¸ëª…: gpt-4o-mini\n- í‰ê°€ ë¡œì§: ë‚®ì€ ì ìˆ˜ì¼ ë•Œ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰\n- Context ëˆ„ì : ê¸°ì¡´ ê²€ìƒ‰ ê²°ê³¼ì— ìƒˆ ê²°ê³¼ ì¶”ê°€ (ë®ì–´ì“°ì§€ ì•ŠìŒ)\n- ë¬´í•œ ë£¨í”„ ë°©ì§€: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ì œí•œ\n- ì—ëŸ¬ ì²˜ë¦¬: ê° ë…¸ë“œì—ì„œ ì˜ˆì™¸ ì²˜ë¦¬"
  },
  {
   "cell_type": "markdown",
   "id": "ysjrngmhma",
   "source": "## 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n\n### ì´ë¡ \n`.env` íŒŒì¼ì—ì„œ API í‚¤ë¥¼ ì•ˆì „í•˜ê²Œ ë¡œë“œí•©ë‹ˆë‹¤.\n- `OPENAI_API_KEY`: OpenAI API ì‚¬ìš©ì„ ìœ„í•œ í‚¤\n- `TAVILY_API_KEY`: Tavily ê²€ìƒ‰ API ì‚¬ìš©ì„ ìœ„í•œ í‚¤\n\n### ì½”ë“œ ì„¤ëª…\n- `load_dotenv()`: `.env` íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ì½ê¸°",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T03:16:39.185497Z",
     "start_time": "2025-10-13T03:16:39.178709Z"
    }
   },
   "source": [
    "# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6tarabpyoam",
   "source": "## 2. LLM ì´ˆê¸°í™”\n\n### ì´ë¡ \n**Temperature** íŒŒë¼ë¯¸í„°:\n- `temperature=0`: ê²°ì •ì (deterministic) ì¶œë ¥, í•­ìƒ ê°™ì€ ë‹µë³€\n- ë†’ì„ìˆ˜ë¡ ì°½ì˜ì ì´ì§€ë§Œ ì¼ê´€ì„±ì´ ë–¨ì–´ì§\n- í‰ê°€ì™€ ê°™ì€ ì‘ì—…ì—ëŠ” 0ì´ ì í•©\n\n### ì½”ë“œ ì„¤ëª…\n- `ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)`: ì¼ê´€ëœ ë‹µë³€ì„ ìœ„í•œ LLM ì„¤ì •",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "llm_setup",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T03:16:39.837468Z",
     "start_time": "2025-10-13T03:16:39.218479Z"
    }
   },
   "source": [
    "# LLM ì´ˆê¸°í™” (ìˆ˜ì •: gpt-4o-minië¡œ ë³€ê²½)\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "tcmiql1nwxo",
   "source": "## 3. AgentState ì •ì˜\n\n### ì´ë¡ \n**í™•ì¥ëœ State êµ¬ì¡°**:\nì´ ë…¸íŠ¸ë¶ì˜ StateëŠ” ë” ë³µì¡í•©ë‹ˆë‹¤:\n- `query`: ì‚¬ìš©ì ì§ˆë¬¸ (ë³€í•˜ì§€ ì•ŠìŒ)\n- `context`: **ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ëˆ„ì í•˜ëŠ” ë¦¬ìŠ¤íŠ¸**\n- `answer`: ìƒì„±ëœ ë‹µë³€\n- `search_threshold`: ê²€ìƒ‰ íŠ¸ë¦¬ê±° ê¸°ì¤€ ì ìˆ˜ (ì´ ì ìˆ˜ ì´í•˜ë©´ ê²€ìƒ‰)\n- `iteration_count`: í˜„ì¬ ë°˜ë³µ íšŸìˆ˜\n- `max_iterations`: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ (ë¬´í•œ ë£¨í”„ ë°©ì§€)\n- `evaluation_score`: ë‹µë³€ í‰ê°€ ì ìˆ˜\n- `evaluation_comment`: í‰ê°€ ì½”ë©˜íŠ¸\n- `error`: ì—ëŸ¬ ë©”ì‹œì§€\n\n**ë°˜ë³µ ì œì–´ ë©”ì»¤ë‹ˆì¦˜**:\n- `iteration_count`ê°€ `max_iterations`ì— ë„ë‹¬í•˜ë©´ ê°•ì œ ì¢…ë£Œ\n- `search_threshold`ë¡œ ë‹µë³€ í’ˆì§ˆ íŒë‹¨\n\n### ì½”ë“œ ì„¤ëª…\n- `TypedDict`: ê° í•„ë“œì— íƒ€ì… ì§€ì •\n- `StateGraph(AgentState)`: ì´ Stateë¥¼ ì‚¬ìš©í•˜ëŠ” ê·¸ë˜í”„ ìƒì„±",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "state_definition",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T03:16:40.926157Z",
     "start_time": "2025-10-13T03:16:40.857084Z"
    }
   },
   "source": [
    "# State ì •ì˜ (ê°œì„ : ë©”íƒ€ë°ì´í„° ì¶”ê°€)\n",
    "from typing_extensions import TypedDict\n",
    "from typing import List, Dict, Any\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    query: str                    # ì‚¬ìš©ì ì§ˆë¬¸\n",
    "    context: List[Dict[str, Any]] # ì›¹ ê²€ìƒ‰ ê²°ê³¼ ëˆ„ì  ë¦¬ìŠ¤íŠ¸\n",
    "    answer: str                   # ìƒì„±ëœ ë‹µë³€\n",
    "    search_threshold: int         # ì›¹ ê²€ìƒ‰ íŠ¸ë¦¬ê±° ê¸°ì¤€ ì ìˆ˜ (ì´í•˜ë©´ ê²€ìƒ‰)\n",
    "    iteration_count: int          # í˜„ì¬ ë°˜ë³µ íšŸìˆ˜\n",
    "    max_iterations: int           # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜\n",
    "    evaluation_score: int         # ë§ˆì§€ë§‰ í‰ê°€ ì ìˆ˜\n",
    "    evaluation_comment: str       # í‰ê°€ ì½”ë©˜íŠ¸\n",
    "    error: str                    # ì—ëŸ¬ ë©”ì‹œì§€\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(AgentState)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0gccibgq6og",
   "source": "## 4. Generate ë…¸ë“œ (ë‹µë³€ ìƒì„±)\n\n### ì´ë¡ \n**ë‘ ê°€ì§€ í”„ë¡¬í”„íŠ¸ ì „ëµ**:\n1. `context_prompt`: ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆì„ ë•Œ\n   - ê²€ìƒ‰ ìë£Œë¥¼ í™œìš©í•˜ì—¬ êµ¬ì²´ì ì¸ ë‹µë³€ ìƒì„±\n   - ì¶œì²˜ ëª…ì‹œ, ìˆ˜ì¹˜ì™€ ë‚ ì§œ í¬í•¨\n2. `simple_prompt`: ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ\n   - ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€\n   - ì‹¤ì‹œê°„ ë°ì´í„°ê°€ í•„ìš”í•¨ì„ ëª…ì‹œ\n\n**Pydantic êµ¬ì¡°í™”ëœ ì¶œë ¥**:\n- `AnswerOutput` í´ë˜ìŠ¤ë¡œ ë‹µë³€ êµ¬ì¡° ì •ì˜\n- `answer`, `confidence`, `sources_used` í•„ë“œ\n- í˜„ì¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ í™•ì¥ ê°€ëŠ¥ì„± ì œê³µ\n\n### ì½”ë“œ ì„¤ëª…\n- `state.get(\"context\", [])`: contextê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜\n- `if context and len(context) > 0`: context ìœ ë¬´ì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©\n- `formatted_context`: ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì½ê¸° ì¢‹ê²Œ í¬ë§·íŒ…\n- `chain = prompt | llm | StrOutputParser()`: LCEL (LangChain Expression Language) ì²´ì¸\n- `return {\"answer\": response, \"iteration_count\": iteration + 1}`: ë‹µë³€ ì €ì¥ ë° ë°˜ë³µ íšŸìˆ˜ ì¦ê°€\n- `try-except`: ì—ëŸ¬ ë°œìƒ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ì €ì¥",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "generate_node",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T03:16:42.441885Z",
     "start_time": "2025-10-13T03:16:42.427141Z"
    }
   },
   "source": [
    "# Generate ë…¸ë“œ (ê°œì„ : êµ¬ì¡°í™”ëœ ì¶œë ¥, ì—ëŸ¬ ì²˜ë¦¬)\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class AnswerOutput(BaseModel):\n",
    "    \"\"\"êµ¬ì¡°í™”ëœ ë‹µë³€ ì¶œë ¥\"\"\"\n",
    "    answer: str = Field(description=\"ì‚¬ìš©ì ì§ˆë¬¸ì— ëŒ€í•œ ìƒì„¸í•œ ë‹µë³€\")\n",
    "    confidence: str = Field(description=\"ë‹µë³€ ì‹ ë¢°ë„: high/medium/low\")\n",
    "    sources_used: bool = Field(description=\"ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì‚¬ìš©í–ˆëŠ”ì§€ ì—¬ë¶€\")\n",
    "\n",
    "\n",
    "# Contextê°€ ìˆì„ ë•Œ ì‚¬ìš©í•˜ëŠ” í”„ë¡¬í”„íŠ¸\n",
    "context_prompt = PromptTemplate.from_template(\"\"\"\n",
    "ë‹¹ì‹ ì€ ì£¼ì‹ íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì›¹ ê²€ìƒ‰ ìë£Œ(context)ì— ê¸°ë°˜í•˜ì—¬ ì§ˆë¬¸(question)ì— ëŒ€í•œ ë‹µì„ ì œê³µí•˜ì„¸ìš”.\n",
    "\n",
    "ê²€ìƒ‰ ìë£Œ:\n",
    "{context}\n",
    "\n",
    "ì§ˆë¬¸: {query}\n",
    "\n",
    "ë‹µë³€ ì‘ì„± ì§€ì¹¨:\n",
    "1. ê²€ìƒ‰ ìë£Œì˜ ì •ë³´ë¥¼ ì •í™•íˆ ì¸ìš©í•˜ì„¸ìš”\n",
    "2. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ë‚ ì§œë¥¼ í¬í•¨í•˜ì„¸ìš”\n",
    "3. ì¶œì²˜ê°€ ëª…í™•í•˜ì§€ ì•Šì€ ì¶”ì¸¡ì€ í”¼í•˜ì„¸ìš”\n",
    "4. ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”\n",
    "\"\"\")\n",
    "\n",
    "# Contextê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•˜ëŠ” í”„ë¡¬í”„íŠ¸\n",
    "simple_prompt = PromptTemplate.from_template(\"\"\"\n",
    "ë‹¹ì‹ ì€ ì£¼ì‹ íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.\n",
    "\n",
    "ì§ˆë¬¸: {query}\n",
    "\n",
    "ë‹µë³€ ì‘ì„± ì§€ì¹¨:\n",
    "1. ì¼ë°˜ì ì¸ íˆ¬ì ì›ì¹™ê³¼ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”\n",
    "2. ì‹¤ì‹œê°„ ë°ì´í„°ê°€ í•„ìš”í•œ ê²½ìš° ê·¸ ì ì„ ëª…ì‹œí•˜ì„¸ìš”\n",
    "3. ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "def generate(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë…¸ë“œ\n",
    "    - Contextê°€ ìˆìœ¼ë©´ ì´ë¥¼ í™œìš©í•˜ì—¬ ë‹µë³€ ìƒì„±\n",
    "    - Contextê°€ ì—†ìœ¼ë©´ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë‹µë³€\n",
    "    - ì—ëŸ¬ ë°œìƒ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€ ì €ì¥\n",
    "    \"\"\"\n",
    "    try:\n",
    "        query = state[\"query\"]\n",
    "        context = state.get(\"context\", [])\n",
    "        iteration = state.get(\"iteration_count\", 0)\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"[Generate] Iteration {iteration + 1}\")\n",
    "        print(f\"Context ê°œìˆ˜: {len(context)}\")\n",
    "        \n",
    "        if context and len(context) > 0:\n",
    "            # Contextë¥¼ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…\n",
    "            formatted_context = \"\\n\\n\".join([\n",
    "                f\"[ì¶œì²˜ {i+1}]\\nì œëª©: {item.get('title', 'N/A')}\\në‚´ìš©: {item.get('content', item.get('raw_content', 'N/A')[:500])}\\nURL: {item.get('url', 'N/A')}\"\n",
    "                for i, item in enumerate(context)\n",
    "            ])\n",
    "            \n",
    "            chain = context_prompt | llm | StrOutputParser()\n",
    "            response = chain.invoke({\"context\": formatted_context, \"query\": query})\n",
    "            return {\n",
    "                \"answer\": response,\n",
    "                \"iteration_count\": iteration + 1\n",
    "            }\n",
    "        else:\n",
    "            chain = simple_prompt | llm | StrOutputParser()\n",
    "            response = chain.invoke({\"query\": query})\n",
    "            return {\n",
    "                \"answer\": response,\n",
    "                \"iteration_count\": iteration + 1\n",
    "            }\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Generate í•¨ìˆ˜ ì—ëŸ¬: {str(e)}\"\n",
    "        print(f\"âŒ {error_msg}\")\n",
    "        return {\n",
    "            \"error\": error_msg,\n",
    "            \"answer\": \"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\"\n",
    "        }"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "drt6uby4vr",
   "source": "## 5. QA í‰ê°€ ë…¸ë“œ\n\n### ì´ë¡ \n**í‰ê°€ ê¸°ì¤€ (20ì  ë§Œì )**:\n1. ì •í™•ì„± (0-5ì ): ë‹µë³€ì´ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µí•˜ëŠ”ê°€?\n2. ì™„ì „ì„± (0-5ì ): ë‹µë³€ì´ ì¶©ë¶„íˆ ìƒì„¸í•œê°€?\n3. ëª…í™•ì„± (0-5ì ): ë‹µë³€ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?\n4. ê´€ë ¨ì„± (0-5ì ): ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆëŠ”ê°€?\n\n**ì¡°ê±´ë¶€ ë¼ìš°íŒ…**:\n- `'enough'`: ì ìˆ˜ >= thresholdì´ê³  ì¶”ê°€ ì •ë³´ ë¶ˆí•„ìš” â†’ ì¢…ë£Œ\n- `'search'`: ì ìˆ˜ < thresholdì´ê±°ë‚˜ ì¶”ê°€ ì •ë³´ í•„ìš” â†’ ì›¹ ê²€ìƒ‰\n- `'max_reached'`: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ â†’ ê°•ì œ ì¢…ë£Œ\n\n**Pydantic Structured Output**:\n- `EvaledAnswer` í´ë˜ìŠ¤ë¡œ í‰ê°€ ê²°ê³¼ êµ¬ì¡°í™”\n- `score`, `comment`, `needs_more_info` í•„ë“œ\n- `with_structured_output()`: LLMì´ ì´ êµ¬ì¡°ë¡œ ì‘ë‹µí•˜ë„ë¡ ê°•ì œ\n\n### ì½”ë“œ ì„¤ëª…\n- `Literal['enough', 'search', 'max_reached']`: ë°˜í™˜ ê°€ëŠ¥í•œ ê°’ ì œí•œ\n- `structured_qa_eval_llm = ChatOpenAI(...).with_structured_output(EvaledAnswer)`: êµ¬ì¡°í™”ëœ ì¶œë ¥ LLM\n- `if state.get(\"error\")`: ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ì¦‰ì‹œ ì¢…ë£Œ\n- `if iteration >= max_iterations`: ìµœëŒ€ ë°˜ë³µ ë„ë‹¬ ì²´í¬\n- `if score >= search_threshold and not needs_more_info`: ì¶©ë¶„í•œ ë‹µë³€ íŒë‹¨\n- `return 'search'`: ì ìˆ˜ ë‚®ê±°ë‚˜ ì¶”ê°€ ì •ë³´ í•„ìš” ì‹œ ê²€ìƒ‰",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "qa_eval_node",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T03:16:43.642474Z",
     "start_time": "2025-10-13T03:16:43.633237Z"
    }
   },
   "source": [
    "# QA í‰ê°€ ë…¸ë“œ (ê°œì„ : ë¡œì§ ìˆ˜ì • - ë‚®ì€ ì ìˆ˜ì¼ ë•Œ ê²€ìƒ‰)\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "class EvaledAnswer(BaseModel):\n",
    "    \"\"\"ë‹µë³€ í‰ê°€ ê²°ê³¼\"\"\"\n",
    "    score: int = Field(..., ge=0, le=20, description=\"ê° ê¸°ì¤€ë³„ ì ìˆ˜ë¥¼ í•©í•œ í•©ì‚° ì ìˆ˜ (0-20)\")\n",
    "    comment: str = Field(description=\"í‰ê°€ê¸°ì¤€ì— ë”°ë¥¸ ìƒì„¸ ì½”ë©˜íŠ¸\")\n",
    "    needs_more_info: bool = Field(description=\"ë” ë§ì€ ì •ë³´ê°€ í•„ìš”í•œì§€ ì—¬ë¶€\")\n",
    "\n",
    "\n",
    "qa_eval_prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"answer\"],\n",
    "    template=\"\"\"\n",
    "ë‹¤ìŒ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ í‰ê°€í•´ì£¼ì„¸ìš”:\n",
    "\n",
    "ì§ˆë¬¸: {question}\n",
    "ë‹µë³€: {answer}\n",
    "\n",
    "í‰ê°€ ê¸°ì¤€ (ê° 0-5ì , ì´ 20ì ):\n",
    "1. ì •í™•ì„± (0-5ì ): ë‹µë³€ì´ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µí•˜ê³  ìˆëŠ”ê°€?\n",
    "2. ì™„ì „ì„± (0-5ì ): ë‹µë³€ì´ ì¶©ë¶„íˆ ìƒì„¸í•˜ê³  ì™„ì „í•œê°€?\n",
    "3. ëª…í™•ì„± (0-5ì ): ë‹µë³€ì´ ì´í•´í•˜ê¸° ì‰½ê³  ëª…í™•í•œê°€?\n",
    "4. ê´€ë ¨ì„± (0-5ì ): ë‹µë³€ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ì´ ìˆëŠ”ê°€?\n",
    "\n",
    "í‰ê°€ ì‹œ ê³ ë ¤ì‚¬í•­:\n",
    "- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ë‚ ì§œ, ì¶œì²˜ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ê°€?\n",
    "- \"ì¸í„°ë„· ê²€ìƒ‰ì´ í•„ìš”í•˜ë‹¤\", \"í™•ì¸í•  ìˆ˜ ì—†ë‹¤\" ë“±ì˜ ë‹µë³€ì€ ë‚®ì€ ì ìˆ˜\n",
    "- ì‹¤ì‹œê°„ ì£¼ê°€, ìµœì‹  ë‰´ìŠ¤ ë“±ì´ í•„ìš”í•œ ê²½ìš° needs_more_infoë¥¼ trueë¡œ ì„¤ì •\n",
    "\n",
    "ê° ê¸°ì¤€ì— ëŒ€í•´ ì ìˆ˜ë¥¼ ë§¤ê¸°ê³ , í‰ê°€ ê¸°ì¤€ë³„ ì ìˆ˜ë¥¼ ëª¨ë‘ ë”í•œ í•©ì‚° ì ìˆ˜(0-20)ì™€ ê°œì„ ì‚¬í•­ì„ ì œì‹œí•˜ì„¸ìš”.\n",
    "\"\"\"  \n",
    ")\n",
    "\n",
    "structured_qa_eval_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0).with_structured_output(EvaledAnswer)\n",
    "\n",
    "\n",
    "def qa_eval(state: AgentState) -> Literal['enough', 'search', 'max_reached']:\n",
    "    \"\"\"\n",
    "    ë‹µë³€ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ë…¸ë“œ\n",
    "    \n",
    "    ë¡œì§ ê°œì„ :\n",
    "    - ì ìˆ˜ê°€ threshold ì´ìƒì´ë©´ 'enough' (ì¢…ë£Œ)\n",
    "    - ì ìˆ˜ê°€ threshold ë¯¸ë§Œì´ë©´ 'search' (ì›¹ ê²€ìƒ‰)\n",
    "    - max_iterations ë„ë‹¬í•˜ë©´ 'max_reached' (ê°•ì œ ì¢…ë£Œ)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        answer = state[\"answer\"]\n",
    "        query = state[\"query\"]\n",
    "        iteration = state.get(\"iteration_count\", 0)\n",
    "        search_threshold = state.get(\"search_threshold\", 15)\n",
    "        max_iterations = state.get(\"max_iterations\", 3)\n",
    "        \n",
    "        # ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ì¦‰ì‹œ ì¢…ë£Œ\n",
    "        if state.get(\"error\"):\n",
    "            return 'max_reached'\n",
    "        \n",
    "        eval_chain = qa_eval_prompt | structured_qa_eval_llm\n",
    "        response = eval_chain.invoke({\"answer\": answer, \"question\": query})\n",
    "        \n",
    "        score = response.score\n",
    "        comment = response.comment\n",
    "        needs_more_info = response.needs_more_info\n",
    "        \n",
    "        print(f\"\\n[QA Eval] Iteration {iteration}\")\n",
    "        print(f\"í‰ê°€ ì ìˆ˜: {score}/20\")\n",
    "        print(f\"ì½”ë©˜íŠ¸: {comment}\")\n",
    "        print(f\"ì¶”ê°€ ì •ë³´ í•„ìš”: {needs_more_info}\")\n",
    "        \n",
    "        # State ì—…ë°ì´íŠ¸\n",
    "        state[\"evaluation_score\"] = score\n",
    "        state[\"evaluation_comment\"] = comment\n",
    "        \n",
    "        # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ ì²´í¬\n",
    "        if iteration >= max_iterations:\n",
    "            print(f\"âš ï¸ ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜({max_iterations}) ë„ë‹¬. ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            return 'max_reached'\n",
    "        \n",
    "        # ì ìˆ˜ê°€ threshold ì´ìƒì´ê³  ì¶”ê°€ ì •ë³´ ë¶ˆí•„ìš”í•˜ë©´ ì¢…ë£Œ\n",
    "        if score >= search_threshold and not needs_more_info:\n",
    "            print(f\"âœ… ì ìˆ˜ê°€ threshold({search_threshold}) ì´ìƒì…ë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            return 'enough'\n",
    "        \n",
    "        # ì ìˆ˜ê°€ ë‚®ê±°ë‚˜ ì¶”ê°€ ì •ë³´ í•„ìš”í•˜ë©´ ì›¹ ê²€ìƒ‰\n",
    "        print(f\"ğŸ” ì ìˆ˜ê°€ ë‚®ê±°ë‚˜ ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì›¹ ê²€ìƒ‰ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\")\n",
    "        return 'search'\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"QA Eval í•¨ìˆ˜ ì—ëŸ¬: {str(e)}\"\n",
    "        print(f\"âŒ {error_msg}\")\n",
    "        state[\"error\"] = error_msg\n",
    "        return 'max_reached'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "pvw1yk82y8o",
   "source": "## 6. ì›¹ ê²€ìƒ‰ ë…¸ë“œ\n\n### ì´ë¡ \n**Tavily Search API**:\n- ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ ì—”ì§„\n- `max_results=3`: ìµœëŒ€ 3ê°œ ê²°ê³¼\n- `search_depth=\"advanced\"`: ê³ ê¸‰ ê²€ìƒ‰ (ë” ê¹Šì€ ë¶„ì„)\n- `include_answer=True`: Tavilyê°€ ìƒì„±í•œ ìš”ì•½ ë‹µë³€ í¬í•¨\n- `include_raw_content=True`: ì›ë³¸ ì½˜í…ì¸  í¬í•¨\n- `include_images=False`: ì´ë¯¸ì§€ ì œì™¸ (í† í° ì ˆì•½)\n\n**Context ëˆ„ì  ì „ëµ**:\n- ê¸°ì¡´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ **ë®ì–´ì“°ì§€ ì•Šê³ ** ìƒˆ ê²°ê³¼ë¥¼ **ì¶”ê°€**\n- ì¤‘ë³µ URL ì œê±°ë¡œ ë™ì¼í•œ ì¶œì²˜ ë°©ì§€\n- ë°˜ë³µë§ˆë‹¤ ë” ë§ì€ ì •ë³´ ì¶•ì \n\n### ì½”ë“œ ì„¤ëª…\n- `TavilySearch(...)`: Tavily ê²€ìƒ‰ ë„êµ¬ ì´ˆê¸°í™”\n- `existing_context = state.get(\"context\", [])`: ê¸°ì¡´ context ê°€ì ¸ì˜¤ê¸°\n- `results = tavily_search_tool.invoke(query)`: ì›¹ ê²€ìƒ‰ ì‹¤í–‰\n- `existing_urls = {item.get('url') for item in existing_context}`: ê¸°ì¡´ URL ì„¸íŠ¸\n- `new_results = [result for result in results if result.get('url') not in existing_urls]`: ì¤‘ë³µ ì œê±°\n- `updated_context = existing_context + new_results`: **ëˆ„ì ** (ë®ì–´ì“°ê¸° X)\n- `return {\"context\": updated_context}`: ì—…ë°ì´íŠ¸ëœ context ë°˜í™˜",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "web_search_node",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T03:16:44.891519Z",
     "start_time": "2025-10-13T03:16:44.698959Z"
    }
   },
   "source": "# Web Search ë…¸ë“œ (ê°œì„ : Context ëˆ„ì , ì—ëŸ¬ ì²˜ë¦¬)\nfrom langchain_tavily import TavilySearch\n\ntavily_search_tool = TavilySearch(\n    max_results=3,\n    search_depth=\"advanced\",\n    include_answer=True,\n    include_raw_content=True,\n    include_images=False  # ì´ë¯¸ì§€ëŠ” ì œì™¸í•˜ì—¬ í† í° ì ˆì•½\n)\n\n\ndef web_search(state: AgentState) -> AgentState:\n    \"\"\"\n    ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë…¸ë“œ\n    \n    ê°œì„ :\n    - Contextë¥¼ ëˆ„ì í•˜ì—¬ ì €ì¥ (ë®ì–´ì“°ê¸° X)\n    - ì¤‘ë³µ URL ì œê±°\n    - ì—ëŸ¬ ì²˜ë¦¬\n    \"\"\"\n    try:\n        query = state[\"query\"]\n        existing_context = state.get(\"context\", [])\n        iteration = state.get(\"iteration_count\", 0)\n        \n        print(f\"\\n[Web Search] ê²€ìƒ‰ ì¿¼ë¦¬: {query}\")\n        \n        # ì›¹ ê²€ìƒ‰ ì‹¤í–‰\n        results = tavily_search_tool.invoke(query)\n        \n        if not results:\n            print(\"âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n            return {\"error\": \"ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\"}\n        \n        print(f\"âœ… ê²€ìƒ‰ ê²°ê³¼ {len(results)}ê°œ ë°œê²¬\")\n        \n        # ê¸°ì¡´ URL ì¶”ì¶œ\n        existing_urls = {item.get('url') for item in existing_context if item.get('url')}\n        \n        # ìƒˆë¡œìš´ ê²°ê³¼ë§Œ ì¶”ê°€ (ì¤‘ë³µ ì œê±°)\n        new_results = [\n            result for result in results \n            if result.get('url') not in existing_urls\n        ]\n        \n        # Context ëˆ„ì \n        updated_context = existing_context + new_results\n        \n        print(f\"ìƒˆë¡œìš´ ê²€ìƒ‰ ê²°ê³¼: {len(new_results)}ê°œ\")\n        print(f\"ì´ Context: {len(updated_context)}ê°œ\")\n        \n        # ì¶œì²˜ ì¶œë ¥\n        for i, result in enumerate(new_results):\n            print(f\"  [{i+1}] {result.get('title', 'N/A')[:50]}...\")\n            print(f\"      {result.get('url', 'N/A')}\")\n        \n        return {\"context\": updated_context}\n        \n    except Exception as e:\n        error_msg = f\"Web Search í•¨ìˆ˜ ì—ëŸ¬: {str(e)}\"\n        print(f\"âŒ {error_msg}\")\n        return {\"error\": error_msg}",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "25863pwz6gu",
   "source": "## 7. ê·¸ë˜í”„ êµ¬ì„±\n\n### ì´ë¡ \n**ì¡°ê±´ë¶€ ì—£ì§€ (Conditional Edge)**:\n- `add_conditional_edges(source, condition_func, edge_mapping)`\n- `condition_func`ì˜ ë°˜í™˜ê°’ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œ ê²°ì •\n- ì´ ì˜ˆì œì—ì„œëŠ” `qa_eval` í•¨ìˆ˜ê°€ ì¡°ê±´ íŒë‹¨\n\n**ì‹¤í–‰ íë¦„**:\n```\nSTART â†’ generate â†’ [qa_eval]\n           â”œâ”€ 'enough' â†’ END (ì¶©ë¶„í•œ ë‹µë³€, ì¢…ë£Œ)\n           â”œâ”€ 'search' â†’ web_search â†’ generate (ì›¹ ê²€ìƒ‰ í›„ ì¬ìƒì„±)\n           â””â”€ 'max_reached' â†’ END (ìµœëŒ€ ë°˜ë³µ ë„ë‹¬, ê°•ì œ ì¢…ë£Œ)\n```\n\n**ìˆœí™˜ êµ¬ì¡°**:\n- `generate â†’ qa_eval â†’ web_search â†’ generate`\n- ë‹µë³€ í’ˆì§ˆì´ ë§Œì¡±ìŠ¤ëŸ¬ìš¸ ë•Œê¹Œì§€ ë°˜ë³µ\n- `max_iterations`ë¡œ ë¬´í•œ ë£¨í”„ ë°©ì§€\n\n### ì½”ë“œ ì„¤ëª…\n- `add_node(\"generate\", generate)`: generate ë…¸ë“œ ì¶”ê°€\n- `add_node(\"web_search\", web_search)`: web_search ë…¸ë“œ ì¶”ê°€\n- `add_edge(START, \"generate\")`: ì‹œì‘í•˜ë©´ generate ì‹¤í–‰\n- `add_conditional_edges('generate', qa_eval, {...})`: generate í›„ ì¡°ê±´ë¶€ ë¼ìš°íŒ…\n  - `qa_eval` í•¨ìˆ˜ì˜ ë°˜í™˜ê°’('enough', 'search', 'max_reached')ì— ë”°ë¼ ë‹¤ìŒ ë…¸ë“œ ê²°ì •\n- `add_edge(\"web_search\", \"generate\")`: ì›¹ ê²€ìƒ‰ í›„ ë‹¤ì‹œ generate\n- `compile()`: ê·¸ë˜í”„ ì»´íŒŒì¼",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "build_graph",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T03:16:51.560312Z",
     "start_time": "2025-10-13T03:16:51.551531Z"
    }
   },
   "source": [
    "# ê·¸ë˜í”„ êµ¬ì„±\n",
    "from langgraph.graph import START, END\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "graph_builder.add_node(\"web_search\", web_search)\n",
    "\n",
    "# ì—£ì§€ ì¶”ê°€\n",
    "graph_builder.add_edge(START, \"generate\")\n",
    "\n",
    "# ì¡°ê±´ë¶€ ì—£ì§€: generate â†’ qa_eval â†’ enough/search/max_reached\n",
    "graph_builder.add_conditional_edges(\n",
    "    'generate',\n",
    "    qa_eval,\n",
    "    {\n",
    "        'enough': END,           # ì¶©ë¶„í•œ ë‹µë³€ â†’ ì¢…ë£Œ\n",
    "        'search': 'web_search',  # ê²€ìƒ‰ í•„ìš” â†’ ì›¹ ê²€ìƒ‰\n",
    "        'max_reached': END       # ìµœëŒ€ ë°˜ë³µ ë„ë‹¬ â†’ ì¢…ë£Œ\n",
    "    }\n",
    ")\n",
    "\n",
    "# ì›¹ ê²€ìƒ‰ â†’ ë‹¤ì‹œ ë‹µë³€ ìƒì„±\n",
    "graph_builder.add_edge(\"web_search\", \"generate\")\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = graph_builder.compile()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a9nag4f6yhw",
   "source": "## 8. ê·¸ë˜í”„ ì‹œê°í™”\n\n### ì½”ë“œ ì„¤ëª…\n- `get_graph().draw_mermaid_png()`: Mermaid ë‹¤ì´ì–´ê·¸ë¨ìœ¼ë¡œ ê·¸ë˜í”„ ì‹œê°í™”\n- ì¡°ê±´ë¶€ ì—£ì§€ì˜ ë¶„ê¸°ì ì„ ì‹œê°ì ìœ¼ë¡œ í™•ì¸ ê°€ëŠ¥\n- ì—ëŸ¬ ë°œìƒ ì‹œ í…ìŠ¤íŠ¸ë¡œ êµ¬ì¡° ì¶œë ¥",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "visualize",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T03:16:53.462845Z",
     "start_time": "2025-10-13T03:16:52.480859Z"
    }
   },
   "source": [
    "# ê·¸ë˜í”„ ì‹œê°í™”\n",
    "from IPython.display import display, Image\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"ê·¸ë˜í”„ ì‹œê°í™” ì‹¤íŒ¨: {e}\")\n",
    "    print(\"í…ìŠ¤íŠ¸ë¡œ ê·¸ë˜í”„ êµ¬ì¡° ì¶œë ¥:\")\n",
    "    print(\"START â†’ generate â†’ [qa_eval]\")\n",
    "    print(\"  â”œâ”€ enough â†’ END\")\n",
    "    print(\"  â”œâ”€ search â†’ web_search â†’ generate\")\n",
    "    print(\"  â””â”€ max_reached â†’ END\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "kzh1esayaxq",
   "source": "## 9. ì‹¤í–‰ í…ŒìŠ¤íŠ¸ (ì‹¤ì‹œê°„ ì£¼ê°€ ì§ˆë¬¸)\n\n### ì´ë¡ \n**ì‹¤ì‹œê°„ ë°ì´í„°ê°€ í•„ìš”í•œ ì§ˆë¬¸**:\n- \"í˜„ì¬ ì£¼ê°€\", \"ìµœê·¼ ë™í–¥\" ë“±ì€ ì›¹ ê²€ìƒ‰ì´ í•„ìˆ˜\n- ì²« ë²ˆì§¸ ë‹µë³€ì€ ë‚®ì€ ì ìˆ˜ë¥¼ ë°›ì„ ê°€ëŠ¥ì„±ì´ ë†’ìŒ\n- ì›¹ ê²€ìƒ‰ í›„ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ì¶œì²˜ê°€ í¬í•¨ëœ ë‹µë³€ ìƒì„±\n\n**ìŠ¤íŠ¸ë¦¼ ëª¨ë“œ**:\n- `graph.stream(state, stream_mode=\"updates\")`: ê° ë…¸ë“œì˜ ì—…ë°ì´íŠ¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°›ìŒ\n- ì§„í–‰ ìƒí™©ì„ printë¬¸ìœ¼ë¡œ í™•ì¸ ê°€ëŠ¥\n\n### ì½”ë“œ ì„¤ëª…\n- `initial_state`: ì´ˆê¸° ìƒíƒœ ì •ì˜\n  - `query`: ì‹¤ì‹œê°„ ì£¼ê°€ ì§ˆë¬¸\n  - `search_threshold=15`: 15ì  ì´ìƒì´ë©´ ì¶©ë¶„\n  - `max_iterations=3`: ìµœëŒ€ 3ë²ˆ ë°˜ë³µ\n- `for update in graph.stream(...)`: ìŠ¤íŠ¸ë¦¼ ëª¨ë“œë¡œ ì‹¤í–‰\n- `final_result = graph.invoke(initial_state)`: ìµœì¢… ê²°ê³¼ ì‹¤í–‰\n- ê²°ê³¼ì—ì„œ ë°˜ë³µ íšŸìˆ˜, í‰ê°€ ì ìˆ˜, ìµœì¢… ë‹µë³€ í™•ì¸",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "run_test",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T03:17:32.063578Z",
     "start_time": "2025-10-13T03:16:54.986760Z"
    }
   },
   "source": [
    "# ì‹¤í–‰ í…ŒìŠ¤íŠ¸\n",
    "from pprint import pprint\n",
    "\n",
    "initial_state = {\n",
    "    'query': '2025ë…„ 10ì›” ì‚¼ì„±ì „ì ì£¼ì‹ì˜ í˜„ì¬ ì£¼ê°€ì™€ ìµœê·¼ ë™í–¥ì„ ì•Œë ¤ì¤˜',\n",
    "    'search_threshold': 15,      # 15ì  ì´ìƒì´ë©´ ì¶©ë¶„\n",
    "    'iteration_count': 0,\n",
    "    'max_iterations': 3,         # ìµœëŒ€ 3ë²ˆ ë°˜ë³µ\n",
    "    'context': [],\n",
    "    'answer': '',\n",
    "    'evaluation_score': 0,\n",
    "    'evaluation_comment': '',\n",
    "    'error': ''\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ì£¼ì‹ íˆ¬ì ì±—ë´‡ - ì›¹ ê²€ìƒ‰ ê¸°ë°˜ ë‹µë³€ ìƒì„±\")\n",
    "print(\"=\"*70)\n",
    "print(f\"ì§ˆë¬¸: {initial_state['query']}\")\n",
    "print(f\"ê²€ìƒ‰ threshold: {initial_state['search_threshold']}ì \")\n",
    "print(f\"ìµœëŒ€ ë°˜ë³µ: {initial_state['max_iterations']}íšŒ\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ìŠ¤íŠ¸ë¦¼ ëª¨ë“œë¡œ ì‹¤í–‰\n",
    "for update in graph.stream(initial_state, stream_mode=\"updates\"):\n",
    "    pass  # ê° ë…¸ë“œì˜ printë¬¸ìœ¼ë¡œ ì§„í–‰ìƒí™© ì¶œë ¥\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ì‹¤í–‰\n",
    "final_result = graph.invoke(initial_state)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ìµœì¢… ê²°ê³¼\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nì´ ë°˜ë³µ íšŸìˆ˜: {final_result.get('iteration_count', 0)}\")\n",
    "print(f\"ìµœì¢… í‰ê°€ ì ìˆ˜: {final_result.get('evaluation_score', 0)}/20\")\n",
    "print(f\"í‰ê°€ ì½”ë©˜íŠ¸: {final_result.get('evaluation_comment', 'N/A')}\")\n",
    "print(f\"ì‚¬ìš©ëœ ê²€ìƒ‰ ê²°ê³¼: {len(final_result.get('context', []))}ê°œ\")\n",
    "if final_result.get('error'):\n",
    "    print(f\"âŒ ì—ëŸ¬: {final_result['error']}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"ìµœì¢… ë‹µë³€:\")\n",
    "print(\"=\"*70)\n",
    "print(final_result.get('answer', 'N/A'))\n",
    "print(\"=\"*70)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fmabnsiusps",
   "source": "## 10. ì¼ë°˜ ì§€ì‹ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\n\n### ì´ë¡ \n**ì¼ë°˜ì ì¸ íˆ¬ì ì§€ì‹ ì§ˆë¬¸**:\n- \"ë¶„ì‚° íˆ¬ìì˜ ì¤‘ìš”ì„±\" ê°™ì€ ì§ˆë¬¸ì€ ì›¹ ê²€ìƒ‰ ì—†ì´ë„ ë‹µë³€ ê°€ëŠ¥\n- LLMì˜ ì¼ë°˜ ì§€ì‹ìœ¼ë¡œ ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì„ ìˆ˜ ìˆìŒ\n- í•˜ì§€ë§Œ í‰ê°€ í•¨ìˆ˜ê°€ `needs_more_info=True`ë¥¼ ë°˜í™˜í•˜ë©´ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰\n\n**ë™ì  ë™ì‘**:\n- ê°™ì€ ê·¸ë˜í”„ê°€ ì§ˆë¬¸ì— ë”°ë¼ ë‹¤ë¥´ê²Œ ë™ì‘\n- ì‹¤ì‹œê°„ ë°ì´í„° í•„ìš” â†’ ì›¹ ê²€ìƒ‰\n- ì¼ë°˜ ì§€ì‹ â†’ ë°”ë¡œ ë‹µë³€\n\n### ì½”ë“œ ì„¤ëª…\n- `simple_state`: ì¼ë°˜ ì§€ì‹ ì§ˆë¬¸\n- `graph.invoke(simple_state)`: ê·¸ë˜í”„ ì‹¤í–‰\n- ë°˜ë³µ íšŸìˆ˜ì™€ í‰ê°€ ì ìˆ˜ë¡œ ë™ì‘ í™•ì¸",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "test_without_search",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-13T03:18:27.676964Z",
     "start_time": "2025-10-13T03:17:54.988254Z"
    }
   },
   "source": [
    "# ì›¹ ê²€ìƒ‰ ì—†ì´ë„ ë‹µë³€ ê°€ëŠ¥í•œ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸\n",
    "simple_state = {\n",
    "    'query': 'ì£¼ì‹ íˆ¬ì ì‹œ ë¶„ì‚° íˆ¬ìì˜ ì¤‘ìš”ì„±ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜',\n",
    "    'search_threshold': 15,\n",
    "    'iteration_count': 0,\n",
    "    'max_iterations': 3,\n",
    "    'context': [],\n",
    "    'answer': '',\n",
    "    'evaluation_score': 0,\n",
    "    'evaluation_comment': '',\n",
    "    'error': ''\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ì¼ë°˜ íˆ¬ì ì§€ì‹ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ (ì›¹ ê²€ìƒ‰ ë¶ˆí•„ìš”)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "simple_result = graph.invoke(simple_state)\n",
    "\n",
    "print(f\"\\nìµœì¢… í‰ê°€ ì ìˆ˜: {simple_result.get('evaluation_score', 0)}/20\")\n",
    "print(f\"ë°˜ë³µ íšŸìˆ˜: {simple_result.get('iteration_count', 0)}\")\n",
    "print(f\"\\në‹µë³€:\\n{simple_result.get('answer', 'N/A')}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0p9jqpotmde",
   "source": "## 10. ì‹¤ìŠµ ë¬¸ì œ\n\nì•„ë˜ 10ê°œì˜ ë¬¸ì œë¥¼ ìˆœì„œëŒ€ë¡œ í’€ì–´ë³´ì„¸ìš”. LangGraphì™€ ì›¹ ê²€ìƒ‰ ê¸°ë°˜ Agentë¥¼ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë©ë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "pzk86tm1po",
   "source": "# TODO: AgentStateì˜ í•„ë“œ ì´ë¦„ì„ ëª¨ë‘ ì¶œë ¥í•˜ì„¸ìš”\n# íŒíŠ¸: AgentState.__annotations__.keys()ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”\n\nfields = list(___)  # ë¹ˆì¹¸ì„ ì±„ìš°ì„¸ìš”\nprint(\"AgentState í•„ë“œ ëª©ë¡:\")\nfor field in fields:\n    print(f\"  - {field}\")\n\n# ê¸°ëŒ€ ê²°ê³¼: query, context, answer, search_threshold ë“± 9ê°œ í•„ë“œ",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9lyrp2x3r6",
   "source": "# TODO: \"í…ŒìŠ¤íŠ¸ ì§ˆë¬¸\"ìœ¼ë¡œ ì´ˆê¸° ìƒíƒœë¥¼ ìƒì„±í•˜ì„¸ìš”\nmy_state = {\n    'query': ___,  # ë¹ˆì¹¸ì„ ì±„ìš°ì„¸ìš”\n    'search_threshold': 15,\n    'iteration_count': ___,  # ë¹ˆì¹¸ì„ ì±„ìš°ì„¸ìš”\n    'max_iterations': 3,\n    'context': ___,  # ë¹ˆì¹¸ì„ ì±„ìš°ì„¸ìš” (ë¹ˆ ë¦¬ìŠ¤íŠ¸)\n    'answer': '',\n    'evaluation_score': 0,\n    'evaluation_comment': '',\n    'error': ''\n}\n\nprint(f\"ì§ˆë¬¸: {my_state['query']}\")\nprint(f\"ìµœëŒ€ ë°˜ë³µ: {my_state['max_iterations']}\")\n\n# ê¸°ëŒ€ ê²°ê³¼: ì§ˆë¬¸: í…ŒìŠ¤íŠ¸ ì§ˆë¬¸, ìµœëŒ€ ë°˜ë³µ: 3",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "as6g1fzv5sl",
   "source": "# TODO: ì ìˆ˜ 18ì , ì½”ë©˜íŠ¸ \"ì¢‹ì€ ë‹µë³€ì…ë‹ˆë‹¤\", needs_more_info=Falseì¸ í‰ê°€ ê²°ê³¼ ìƒì„±\neval_result = EvaledAnswer(\n    score=___,  # ë¹ˆì¹¸ì„ ì±„ìš°ì„¸ìš”\n    comment=___,  # ë¹ˆì¹¸ì„ ì±„ìš°ì„¸ìš”\n    needs_more_info=___  # ë¹ˆì¹¸ì„ ì±„ìš°ì„¸ìš”\n)\n\nprint(f\"ì ìˆ˜: {eval_result.score}/20\")\nprint(f\"ì½”ë©˜íŠ¸: {eval_result.comment}\")\nprint(f\"ì¶”ê°€ ì •ë³´ í•„ìš”: {eval_result.needs_more_info}\")\n\n# ê¸°ëŒ€ ê²°ê³¼: ì ìˆ˜: 18/20, ì½”ë©˜íŠ¸: ì¢‹ì€ ë‹µë³€ì…ë‹ˆë‹¤, ì¶”ê°€ ì •ë³´ í•„ìš”: False",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "u0eq5lbfwxd",
   "source": "# TODO: Tavilyë¡œ \"ì‚¼ì„±ì „ì ì£¼ê°€\" ê²€ìƒ‰\nsearch_query = ___  # ë¹ˆì¹¸ì„ ì±„ìš°ì„¸ìš”\nresults = tavily_search_tool.invoke(search_query)\n\nprint(f\"ê²€ìƒ‰ì–´: {search_query}\")\nprint(f\"ê²°ê³¼ ê°œìˆ˜: {len(results)}\")\nprint(f\"\\nì²« ë²ˆì§¸ ê²°ê³¼:\")\nprint(f\"  ì œëª©: {results[0].get('title', 'N/A')[:50]}...\")\nprint(f\"  URL: {results[0].get('url', 'N/A')}\")\n\n# ê¸°ëŒ€ ê²°ê³¼: 3ê°œì˜ ê²€ìƒ‰ ê²°ê³¼ì™€ ì²« ë²ˆì§¸ ê²°ê³¼ì˜ ì œëª©/URL",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "bgkjqhpu8xa",
   "source": "# TODO: ë‚˜ë§Œì˜ ì§ˆë¬¸ìœ¼ë¡œ ê·¸ë˜í”„ ì‹¤í–‰\nmy_question = ___  # ì—¬ê¸°ì— ì§ˆë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”\n\nmy_test_state = {\n    'query': my_question,\n    'search_threshold': 15,\n    'iteration_count': 0,\n    'max_iterations': 2,  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 2ë¡œ ì„¤ì •\n    'context': [],\n    'answer': '',\n    'evaluation_score': 0,\n    'evaluation_comment': '',\n    'error': ''\n}\n\nprint(f\"ì§ˆë¬¸: {my_question}\")\nprint(\"=\"*70)\n\n# ê·¸ë˜í”„ ì‹¤í–‰\nresult = graph.invoke(my_test_state)\n\nprint(f\"\\nìµœì¢… ë‹µë³€:\")\nprint(result.get('answer', 'N/A'))\nprint(f\"\\ní‰ê°€ ì ìˆ˜: {result.get('evaluation_score', 0)}/20\")\n\n# ê¸°ëŒ€ ê²°ê³¼: ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ê³¼ í‰ê°€ ì ìˆ˜",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "yng1hunb0m",
   "source": "# ì •ë‹µ ì˜ˆì‹œ (ì£¼ì„ í•´ì œí•˜ì—¬ í™•ì¸)\n\n# # ë¬¸ì œ 1\n# fields = list(AgentState.__annotations__.keys())\n\n# # ë¬¸ì œ 2\n# my_state = {\n#     'query': \"í…ŒìŠ¤íŠ¸ ì§ˆë¬¸\",\n#     'iteration_count': 0,\n#     'context': []\n# }\n\n# # ë¬¸ì œ 3\n# response = llm.invoke(question)\n\n# # ë¬¸ì œ 4\n# eval_result = EvaledAnswer(\n#     score=18,\n#     comment=\"ì¢‹ì€ ë‹µë³€ì…ë‹ˆë‹¤\",\n#     needs_more_info=False\n# )\n\n# # ë¬¸ì œ 5\n# if score >= threshold and not needs_more_info:\n\n# # ë¬¸ì œ 6\n# return iteration >= max_iter\n\n# # ë¬¸ì œ 7\n# search_query = \"ì‚¼ì„±ì „ì ì£¼ê°€\"\n\n# # ë¬¸ì œ 8\n# updated_context = existing_context + new_results\n\n# # ë¬¸ì œ 9\n# test_graph = StateGraph(AgentState)\n# test_graph.add_node(\"my_node\", my_node)\n\n# # ë¬¸ì œ 10\n# my_question = \"ì£¼ì‹ íˆ¬ìì˜ ê¸°ë³¸ ì›ì¹™ 3ê°€ì§€ëŠ”?\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "tsvth3902t",
   "source": "---\n\n## ì •ë‹µ í™•ì¸\n\nëª¨ë“  ë¬¸ì œë¥¼ í’€ì—ˆë‹¤ë©´, ì•„ë˜ ì…€ì˜ ì£¼ì„ì„ í•´ì œí•˜ì—¬ ì •ë‹µì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "ptfykcdldfs",
   "source": "### ë¬¸ì œ 10: ë‚˜ë§Œì˜ ì›Œí¬í”Œë¡œìš° ë§Œë“¤ê¸°\n\n**ëª©í‘œ**: ê°„ë‹¨í•œ ì§ˆë¬¸ì„ ë§Œë“¤ê³  ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•˜ì—¬ ë‹µë³€ì„ ë°›ì•„ë³´ì„¸ìš”.\n\n**íŒíŠ¸**: \n- `initial_state`ë¥¼ ë§Œë“¤ê³  `graph.invoke()`ë¡œ ì‹¤í–‰í•˜ì„¸ìš”.\n- ì›¹ ê²€ìƒ‰ì´ í•„ìš” ì—†ëŠ” ì¼ë°˜ì ì¸ ì§ˆë¬¸ì„ ì„ íƒí•˜ë©´ ë” ë¹ ë¦…ë‹ˆë‹¤.\n\n**ì¶”ì²œ ì§ˆë¬¸ ì˜ˆì‹œ**:\n- \"ì£¼ì‹ íˆ¬ìì˜ ê¸°ë³¸ ì›ì¹™ 3ê°€ì§€ëŠ”?\"\n- \"ë¶„ì‚° íˆ¬ìê°€ ì¤‘ìš”í•œ ì´ìœ ëŠ”?\"\n- \"ì¥ê¸° íˆ¬ìì™€ ë‹¨ê¸° íˆ¬ìì˜ ì°¨ì´ì ì€?\"",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "xo3i8piilmj",
   "source": "### ë¬¸ì œ 9: StateGraph ë…¸ë“œ ì¶”ê°€í•˜ê¸°\n\n**ëª©í‘œ**: StateGraphì— ìƒˆë¡œìš´ ë…¸ë“œë¥¼ ì¶”ê°€í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n\n**íŒíŠ¸**: `add_node()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "f8s0wfp4usl",
   "source": "### ë¬¸ì œ 8: Context ëˆ„ì  ì´í•´í•˜ê¸°\n\n**ëª©í‘œ**: ê¸°ì¡´ contextì— ìƒˆë¡œìš´ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ëˆ„ì í•˜ëŠ” ë¡œì§ì„ ì‘ì„±í•˜ì„¸ìš”.\n\n**íŒíŠ¸**: ë¦¬ìŠ¤íŠ¸ í•©ì¹˜ê¸°(`+`)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "jpnntp5szpn",
   "source": "### ë¬¸ì œ 7: Tavily ê²€ìƒ‰ API ì‚¬ìš©í•˜ê¸°\n\n**ëª©í‘œ**: Tavily APIë¡œ \"ì‚¼ì„±ì „ì ì£¼ê°€\"ë¥¼ ê²€ìƒ‰í•˜ì„¸ìš”.\n\n**íŒíŠ¸**: `tavily_search_tool.invoke()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "7ngraentwi9",
   "source": "### ë¬¸ì œ 6: ì¡°ê±´ë¶€ ë¡œì§ ì‘ì„±í•˜ê¸°\n\n**ëª©í‘œ**: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ë¥¼ ì²´í¬í•˜ëŠ” ë¡œì§ì„ ì‘ì„±í•˜ì„¸ìš”.\n\n**íŒíŠ¸**: `iteration_count`ì™€ `max_iterations`ë¥¼ ë¹„êµí•˜ì„¸ìš”.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "78nwdotsaxr",
   "source": "# TODO: ìƒˆë¡œìš´ StateGraph ìƒì„±í•˜ê³  ë…¸ë“œ ì¶”ê°€\nfrom langgraph.graph import StateGraph\n\n# ê°„ë‹¨í•œ ë…¸ë“œ í•¨ìˆ˜ ì •ì˜\ndef my_node(state: AgentState) -> AgentState:\n    \\\"\\\"\\\"ê°„ë‹¨í•œ ë…¸ë“œ í•¨ìˆ˜\\\"\\\"\\\"\n    print(\"my_node ì‹¤í–‰!\")\n    return {\"answer\": \"ë…¸ë“œ í…ŒìŠ¤íŠ¸\"}\n\n# StateGraph ìƒì„±\ntest_graph = StateGraph(___)  # ë¹ˆì¹¸ì„ ì±„ìš°ì„¸ìš” (AgentState)\n\n# ë…¸ë“œ ì¶”ê°€\ntest_graph.add_node(___, my_node)  # ë¹ˆì¹¸ì„ ì±„ìš°ì„¸ìš” (\"my_node\")\n\nprint(\"âœ… StateGraph ìƒì„± ë° ë…¸ë“œ ì¶”ê°€ ì™„ë£Œ\")\n\n# ê¸°ëŒ€ ê²°ê³¼: âœ… StateGraph ìƒì„± ë° ë…¸ë“œ ì¶”ê°€ ì™„ë£Œ",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "24uuyp7fjkn",
   "source": "### ë¬¸ì œ 5: í‰ê°€ ì ìˆ˜ ì´í•´í•˜ê¸°\n\n**ëª©í‘œ**: ì ìˆ˜ì— ë”°ë¼ ë‹¤ìŒ í–‰ë™ì„ ê²°ì •í•˜ëŠ” ì¡°ê±´ë¬¸ì„ ì‘ì„±í•˜ì„¸ìš”.\n\n**íŒíŠ¸**: `search_threshold`ì™€ ë¹„êµí•˜ì„¸ìš”.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "p85o52k3um",
   "source": "# TODO: Context ëˆ„ì  ë¡œì§ ì™„ì„±\nexisting_context = [{\"title\": \"ê²°ê³¼1\", \"url\": \"http://example.com/1\"}]\nnew_results = [\n    {\"title\": \"ê²°ê³¼2\", \"url\": \"http://example.com/2\"},\n    {\"title\": \"ê²°ê³¼3\", \"url\": \"http://example.com/3\"}\n]\n\n# ê¸°ì¡´ contextì— ìƒˆ ê²°ê³¼ ì¶”ê°€\nupdated_context = existing_context ___ new_results  # ë¹ˆì¹¸ì„ ì±„ìš°ì„¸ìš” (+)\n\nprint(f\"ê¸°ì¡´ context: {len(existing_context)}ê°œ\")\nprint(f\"ìƒˆ ê²°ê³¼: {len(new_results)}ê°œ\")\nprint(f\"ëˆ„ì  context: {len(updated_context)}ê°œ\")\n\n# ê¸°ëŒ€ ê²°ê³¼: ê¸°ì¡´ context: 1ê°œ, ìƒˆ ê²°ê³¼: 2ê°œ, ëˆ„ì  context: 3ê°œ",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "hgxvpd5rtx",
   "source": "### ë¬¸ì œ 4: Pydanticìœ¼ë¡œ êµ¬ì¡°í™”ëœ ì¶œë ¥ ë§Œë“¤ê¸°\n\n**ëª©í‘œ**: `EvaledAnswer` í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ í‰ê°€ ê²°ê³¼ë¥¼ ìƒì„±í•˜ì„¸ìš”.\n\n**íŒíŠ¸**: Pydantic ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì§ì ‘ ìƒì„±í•˜ì„¸ìš”.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "pr0gtxh553o",
   "source": "### ë¬¸ì œ 3: LLMìœ¼ë¡œ ë‹µë³€ ìƒì„±í•˜ê¸°\n\n**ëª©í‘œ**: `ChatOpenAI`ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨í•œ ì§ˆë¬¸ì— ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.\n\n**íŒíŠ¸**: `llm.invoke()` ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "q3ijiekmht",
   "source": "# TODO: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ì²´í¬ í•¨ìˆ˜ ì™„ì„±\ndef check_max_iterations(iteration: int, max_iter: int) -> bool:\n    \"\"\"ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ì— ë„ë‹¬í–ˆëŠ”ì§€ í™•ì¸\"\"\"\n    return iteration >= ___  # ë¹ˆì¹¸ì„ ì±„ìš°ì„¸ìš”\n\n# í…ŒìŠ¤íŠ¸\nprint(check_max_iterations(3, 3))  # True\nprint(check_max_iterations(2, 3))  # False\nprint(check_max_iterations(4, 3))  # True\n\n# ê¸°ëŒ€ ê²°ê³¼: True, False, True",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "kpssijet6k",
   "source": "### ë¬¸ì œ 2: ê°„ë‹¨í•œ State ìƒì„±í•˜ê¸°\n\n**ëª©í‘œ**: ì´ˆê¸° `AgentState`ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ìƒì„±í•˜ì„¸ìš”.\n\n**íŒíŠ¸**: ìœ„ì˜ `initial_state` ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì„¸ìš”.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "2liif6d73g9",
   "source": "# TODO: ì ìˆ˜ì— ë”°ë¼ í–‰ë™ì„ ê²°ì •í•˜ëŠ” í•¨ìˆ˜ ì™„ì„±\ndef decide_action(score: int, threshold: int, needs_more_info: bool) -> str:\n    \"\"\"ì ìˆ˜ì™€ thresholdë¥¼ ë¹„êµí•˜ì—¬ ë‹¤ìŒ í–‰ë™ ê²°ì •\"\"\"\n    if score >= ___ and not needs_more_info:  # ë¹ˆì¹¸ì„ ì±„ìš°ì„¸ìš”\n        return \"enough\"  # ì¶©ë¶„í•¨, ì¢…ë£Œ\n    else:\n        return \"search\"  # ê²€ìƒ‰ í•„ìš”\n\n# í…ŒìŠ¤íŠ¸\nprint(decide_action(18, 15, False))  # \"enough\"\nprint(decide_action(12, 15, False))  # \"search\"\nprint(decide_action(18, 15, True))   # \"search\"\n\n# ê¸°ëŒ€ ê²°ê³¼: enough, search, search",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "xprnfswulw",
   "source": "### ë¬¸ì œ 1: AgentState íƒ€ì… ì´í•´í•˜ê¸°\n\n**ëª©í‘œ**: `AgentState`ì— ì–´ë–¤ í•„ë“œë“¤ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , ê° í•„ë“œì˜ ì—­í• ì„ ì´í•´í•˜ì„¸ìš”.\n\n**íŒíŠ¸**: `AgentState` í´ë˜ìŠ¤ ì •ì˜ë¥¼ ë‹¤ì‹œ ì½ì–´ë³´ì„¸ìš”.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "zo5sxe4p349",
   "source": "# TODO: \"ì£¼ì‹ íˆ¬ìë€ ë¬´ì—‡ì¸ê°€ìš”?\" ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„±\nquestion = \"ì£¼ì‹ íˆ¬ìë€ ë¬´ì—‡ì¸ê°€ìš”?\"\nresponse = llm.invoke(___)  # ë¹ˆì¹¸ì„ ì±„ìš°ì„¸ìš”\n\nprint(f\"ì§ˆë¬¸: {question}\")\nprint(f\"ë‹µë³€: {response.content[:100]}...\")  # ì²˜ìŒ 100ìë§Œ ì¶œë ¥\n\n# ê¸°ëŒ€ ê²°ê³¼: LLMì´ ìƒì„±í•œ ì£¼ì‹ íˆ¬ìì— ëŒ€í•œ ì„¤ëª…",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6d6fbe58d29a3220"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}